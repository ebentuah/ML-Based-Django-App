{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "# from faker import Faker\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn import pipeline,preprocessing,metrics,model_selection,ensemble\n",
    "import itertools\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\Users\\FinTech\\Desktop\\ml_app\\fruadAPp\\PS_20174392719_1491204439457_log.csv')\n",
    "only_fraud = df[df['isFraud'] == 1] # fishing out non-fraudulent cases\n",
    "not_fraud = df[df['isFraud'] == 0] # fishing out fraudulent cases\n",
    "data_notFraud = not_fraud.sample(n = 1000000, random_state = 0) # randomly selecting 1M non-fraudulent cases from the dataset \n",
    "fraud_dataframe = pd.concat([only_fraud, data_notFraud], axis=0)  # Joining them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_dataframe['oldbalanceDest'].unique()\n",
    "# fraud_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper = DataFrameMapper([\n",
    "#                         (['nameOrig'], preprocessing.OneHotEncoder()),\n",
    "#                         (['nameDest'], preprocessing.OneHotEncoder()),\n",
    "#                         (['type'], preprocessing.OneHotEncoder()),\n",
    "#                         (['step'], preprocessing.MinMaxScaler()),\n",
    "#                         (['type'], preprocessing.MinMaxScaler()),\n",
    "#                         (['amount'], preprocessing.MinMaxScaler()),\n",
    "#                         (['nameOrig'], preprocessing.MinMaxScaler()),\n",
    "#                         (['oldbalanceOrg'], preprocessing.MinMaxScaler()),\n",
    "#                         (['newbalanceOrig'], preprocessing.MinMaxScaler()),\n",
    "#                         (['nameDest'], preprocessing.MinMaxScaler()),\n",
    "#                         (['oldbalanceDest'], preprocessing.MinMaxScaler()),\n",
    "#                         (['newbalanceDest'], preprocessing.MinMaxScaler()),\n",
    "#                         (['step'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['type'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['amount'],preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['nameOrig'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['oldbalanceOrg'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['newbalanceOrig'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['nameDest'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['oldbalanceDest'], preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#                         (['newbalanceDest'], preprocessing.PolynomialFeatures(degree=2, include_bias=False))\n",
    "#                         ], df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_obj = pipeline.Pipeline([\n",
    "#     ('mapper',mapper),\n",
    "#     (\"model\", XGBClassifier(objective= 'binary:logistic',nthread=4,seed=0,learning_rate = 0.1,n_estimators=1000))\n",
    "# ])\n",
    "# mapper.head()\n",
    "# X=['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "#        'nameDest', 'oldbalanceDest', 'newbalanceDest']\n",
    "# Y=['isFraud']\n",
    "# pipeline_obj.fit(fraud_dataframe[X],fraud_dataframe[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_edit(fraud_dataframe):\n",
    "    label = LabelEncoder()\n",
    "    fraud_dataframe['nameOrig'] = label.fit_transform(fraud_dataframe['nameOrig']) #encoding the nameorig\n",
    "    fraud_dataframe['nameDest']= label.fit_transform(fraud_dataframe['nameDest'])\n",
    "    fraud_dataframe['type']= label.fit_transform(fraud_dataframe['type'])#encoding the namedest\n",
    "    df1 = pd.get_dummies(fraud_dataframe) # making dummies on the type of transaction\n",
    "    features = df1.drop(['isFraud','isFlaggedFraud'],axis=1)\n",
    "    \n",
    "    #preprocessing the data using scalers\n",
    "    scaler = MinMaxScaler() # to reduce higher spread of dimentionality and outliers\n",
    "    scaler.fit(features)\n",
    "    featuress = scaler.transform(features)\n",
    "    feat_poly = PolynomialFeatures(degree=2, include_bias=False).fit_transform(featuress) #adding polynomial features\n",
    "    return feat_poly \n",
    "\n",
    "X = df_edit(fraud_dataframe)\n",
    "target = fraud_dataframe['isFraud'] # making the isFraud column the target variable. \n",
    "\n",
    "# Splitting the dataset.    \n",
    "X_train,X_test,y_train,y_test = train_test_split(X, target, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "   \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "# dtf_model = DecisionTreeClassifier(max_features='auto', random_state=0, splitter ='best',max_depth = 1000, class_weight={0:1, 1:12},  max_leaf_nodes=150)\n",
    "# rf_model = RandomForestClassifier(n_estimators=1000,class_weight={0:1, 1:12}, bootstrap = True, max_depth=100)\n",
    "\n",
    "xbg_model = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    seed=0,\n",
    "    learning_rate = 0.1,\n",
    "    n_estimators=1000\n",
    ")\n",
    "\n",
    "xbg_model.fit(X_train, y_train)\n",
    "predictions = xbg_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "#plotting confusion matrix. \n",
    "cnf_matrix_tra = confusion_matrix(y_test, predictions)\n",
    "print(\"Recall metric in the test dataset: {}%\".format(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1])))\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tra , classes=class_names, title='Confusion matrix of the test  dataset') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_ver = df[100000:900000] \n",
    "df_ver_classes = pd.value_counts(df_ver['isFraud'], sort=True)\n",
    "#df_ver_classes\n",
    "target_vali = df_ver['isFraud']\n",
    "\n",
    "features_vali = df_edit(df_ver)\n",
    "\n",
    "predict_valid = xbg_model.predict(features_vali)\n",
    "print(metrics.classification_report(target_vali, predict_valid))\n",
    "\n",
    "#plotting confusion matrix. \n",
    "cnf_matrix_tra = confusion_matrix(target_vali, predict_valid)\n",
    "print(\"Recall metric in the validation dataset: {}%\".format(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1])))\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tra , classes=class_names, title='Confusion matrix of the validation  dataset') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "joblib.dump(xbg_model,'RFModelforfraud_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelReload=joblib.load('RFModelforfraud_2.pkl')\n",
    "\n",
    "modelReload.predict(features_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp={}\n",
    "temp['step']=100\n",
    "temp['type']= 'TRANSFER'\n",
    "temp['amount']=47664\n",
    "temp['nameOrig']= 'C1720120297'\n",
    "temp['oldbalanceOrg']=500000\n",
    "temp['newbalanceOrig']=100664\n",
    "temp['nameDest']= 'C496863720'\n",
    "temp['oldbalanceDest']=1605021.18\n",
    "temp['newbalanceDest']=1000000.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDtaa=pd.DataFrame({'x':temp}).transpose()\n",
    "testDtaa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_edit_2(fraud_dataframe):\n",
    "    label = LabelEncoder()\n",
    "    fraud_dataframe['nameOrig'] = label.fit_transform(fraud_dataframe['nameOrig']) #encoding the nameorig\n",
    "    fraud_dataframe['nameDest']= label.fit_transform(fraud_dataframe['nameDest'])\n",
    "    fraud_dataframe['type']= label.fit_transform(fraud_dataframe['type'])#encoding the namedest\n",
    "    df1 = pd.get_dummies(fraud_dataframe) # making dummies on the type of transaction\n",
    "#     features = df1.drop(['isFraud','isFlaggedFraud'],axis=1)\n",
    "    \n",
    "    #preprocessing the data using scalers\n",
    "    scaler = MinMaxScaler() # to reduce higher spread of dimentionality and outliers\n",
    "    scaler.fit(df1)\n",
    "    featuress = scaler.transform(df1)\n",
    "    feat_poly = PolynomialFeatures(degree=2, include_bias=False).fit_transform(featuress) #adding polynomial features\n",
    "    return feat_poly \n",
    "\n",
    "\n",
    "\n",
    "fraud = df_edit_2(testDtaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelReload.predict(fraud)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
